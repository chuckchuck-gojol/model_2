{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 2 - 기능 3에 대해 추가 처리 가능한 모델2 작성 (1)\n",
    "#### 모델 2는 모델 1에서 기능 3 지하철 트리거 인식 시 작동되는 모델임\n",
    "#### 모델 1에서 기능 3으로 분류(카테고리 :3) 인 경우 해당 모델에서 역별 분류 작업 수행\n",
    "#### 최종 수정일 : 20-05-27\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 2. 모델링\n",
    "### 2.1 데이터 구성\n",
    "\n",
    "> [변경사항]\n",
    "\n",
    "* * *\n",
    "> [기존과 동일]\n",
    "- model_1.npz 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 193), (129, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 알림, 차량 엔진, 차량 경적, 지하철 트리거 순\n",
    "sound_data = np.load('data.npz')\n",
    "X_train = sound_data['X']\n",
    "y_train = sound_data['y']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 193), (129, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 2. 모델링\n",
    "### 2.2 모델 학습\n",
    "\n",
    "> [변경사항]\n",
    "- lstm 사용\n",
    "- 이전 모델의 경우 파라미터 조정에 초점을 두었으나 ver 3.5에서는 layer 구성에 초점을 두어 진행\n",
    "* * *\n",
    "> [기존과 동일]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential() # Sequeatial Model\n",
    "model.add(LSTM(20, input_shape=(193, 1))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.values\n",
    "X_train = X_train.reshape(X_train.shape[0], 193, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 157.3219\n",
      "Epoch 2/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 157.1995\n",
      "Epoch 3/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 157.1315\n",
      "Epoch 4/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.9902\n",
      "Epoch 5/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 156.9106\n",
      "Epoch 6/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 156.7834\n",
      "Epoch 7/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.7113\n",
      "Epoch 8/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 156.6118\n",
      "Epoch 9/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.5275\n",
      "Epoch 10/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.4403\n",
      "Epoch 11/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.3570\n",
      "Epoch 12/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.3056\n",
      "Epoch 13/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.2438\n",
      "Epoch 14/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 156.1680\n",
      "Epoch 15/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 156.1049\n",
      "Epoch 16/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 156.0463\n",
      "Epoch 17/100\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 155.9948\n",
      "Epoch 18/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.9589\n",
      "Epoch 19/100\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 155.9021\n",
      "Epoch 20/100\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 155.8680\n",
      "Epoch 21/100\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 155.8490\n",
      "Epoch 22/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.7812\n",
      "Epoch 23/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.7498\n",
      "Epoch 24/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.6919\n",
      "Epoch 25/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.6362\n",
      "Epoch 26/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.5798\n",
      "Epoch 27/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.5300\n",
      "Epoch 28/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.4614\n",
      "Epoch 29/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.4012\n",
      "Epoch 30/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.3422\n",
      "Epoch 31/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.3108\n",
      "Epoch 32/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.2322\n",
      "Epoch 33/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.1981\n",
      "Epoch 34/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.1522\n",
      "Epoch 35/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.1191\n",
      "Epoch 36/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.0895\n",
      "Epoch 37/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.0740\n",
      "Epoch 38/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.0509\n",
      "Epoch 39/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 155.0339\n",
      "Epoch 40/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 155.0177\n",
      "Epoch 41/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.9845\n",
      "Epoch 42/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 154.9601\n",
      "Epoch 43/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 154.9495\n",
      "Epoch 44/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.9116\n",
      "Epoch 45/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.8950\n",
      "Epoch 46/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.8810\n",
      "Epoch 47/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.8627\n",
      "Epoch 48/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.8426\n",
      "Epoch 49/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.8128\n",
      "Epoch 50/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.7817\n",
      "Epoch 51/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 154.7616\n",
      "Epoch 52/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 154.7284\n",
      "Epoch 53/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 154.7354\n",
      "Epoch 00053: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f242f21c48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          batch_size=30, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 2. 모델링\n",
    "### 2.3 모델 저장\n",
    "\n",
    "> [변경사항]\n",
    "- pkl, json, pb, tflite로 저장\n",
    "* * *\n",
    "> [기존과 동일]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_2.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 pkl로 저장하기\n",
    "import joblib\n",
    "joblib.dump(model, 'model_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 json으로 저장하기\n",
    "model_2 = model.to_json()\n",
    "# model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 h5로 저장하기\n",
    "from keras.models import load_model\n",
    "model.save('model_2')\n",
    "model.save('model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/pb/assets\n"
     ]
    }
   ],
   "source": [
    "# 모델 pb로 저장하기\n",
    "model = keras.models.load_model('model_2', compile=False)\n",
    "model.save('model/pb/',save_format=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2020-05-27 21:43:09.825377: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-27 21:43:09.825766: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2020-05-27 21:43:14.295202: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2020-05-27 21:43:14.296981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n2020-05-27 21:43:14.324665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0\ncoreClock: 1.2415GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 14.92GiB/s\n2020-05-27 21:43:14.326032: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-27 21:43:14.327198: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found\n2020-05-27 21:43:14.328262: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n2020-05-27 21:43:14.329370: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n2020-05-27 21:43:14.330462: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\n2020-05-27 21:43:14.331518: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found\n2020-05-27 21:43:14.332580: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\n2020-05-27 21:43:14.332932: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2020-05-27 21:43:14.388539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n2020-05-27 21:43:14.388843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n2020-05-27 21:43:14.389035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n2020-05-27 21:43:14.402583: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\n2020-05-27 21:43:14.402910: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.403189: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\n2020-05-27 21:43:14.403452: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.403708: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\n2020-05-27 21:43:14.403963: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.404205: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.404456: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\n2020-05-27 21:43:14.405822: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 20 operators, 56 arrays (0 quantized)\n2020-05-27 21:43:14.406713: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 20 operators, 56 arrays (0 quantized)\n2020-05-27 21:43:14.410342: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.410864: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.411314: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.411747: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.412272: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 832 bytes, theoretical optimal value: 832 bytes.\n2020-05-27 21:43:14.412670: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 1817\n2020-05-27 21:43:14.414782: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.415172: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.415542: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.415893: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.416331: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.416700: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.417067: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.417435: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.417863: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\nTraceback (most recent call last):\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\jih02\\AppData\\Local\\Continuum\\anaconda3\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-1f26f02537b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS,\n\u001b[0;32m      5\u001b[0m                                      tf.lite.OpsSet.SELECT_TF_OPS]\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtfilte_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/tflite/model_1.tflite'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mftlite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m         **converter_kwargs)\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[0;32m    458\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# Must manually cleanup files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: See console for info.\n2020-05-27 21:43:09.825377: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-27 21:43:09.825766: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2020-05-27 21:43:14.295202: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2020-05-27 21:43:14.296981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n2020-05-27 21:43:14.324665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce 940MX computeCapability: 5.0\ncoreClock: 1.2415GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 14.92GiB/s\n2020-05-27 21:43:14.326032: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n2020-05-27 21:43:14.327198: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found\n2020-05-27 21:43:14.328262: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n2020-05-27 21:43:14.329370: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n2020-05-27 21:43:14.330462: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\n2020-05-27 21:43:14.331518: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found\n2020-05-27 21:43:14.332580: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\n2020-05-27 21:43:14.332932: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2020-05-27 21:43:14.388539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n2020-05-27 21:43:14.388843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n2020-05-27 21:43:14.389035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n2020-05-27 21:43:14.402583: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\n2020-05-27 21:43:14.402910: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.403189: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\n2020-05-27 21:43:14.403452: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.403708: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\n2020-05-27 21:43:14.403963: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.404205: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\n2020-05-27 21:43:14.404456: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\n2020-05-27 21:43:14.405822: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 20 operators, 56 arrays (0 quantized)\n2020-05-27 21:43:14.406713: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 20 operators, 56 arrays (0 quantized)\n2020-05-27 21:43:14.410342: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.410864: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.411314: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.411747: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 7 operators, 36 arrays (0 quantized)\n2020-05-27 21:43:14.412272: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 832 bytes, theoretical optimal value: 832 bytes.\n2020-05-27 21:43:14.412670: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 1817\n2020-05-27 21:43:14.414782: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.415172: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.415542: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.415893: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.416331: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListFromTensor is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.416700: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListReserve is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.417067: W tensorflow/lite/toco/tflite/operator.cc:2024] Op While is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.417435: W tensorflow/lite/toco/tflite/operator.cc:2024] Op TensorListStack is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\n2020-05-27 21:43:14.417863: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\nTraceback (most recent call last):\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\jih02\\AppData\\Local\\Continuum\\anaconda3\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\jih02\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\n\n"
     ]
    }
   ],
   "source": [
    "#모델 tflite 로 저장하기\n",
    "saved_model_dir='model/pb/'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                     tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tfilte_mode=converter.convert()\n",
    "open('model/tflite/model_1.tflite','wb').write(ftlite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
