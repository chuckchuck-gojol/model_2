{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 2 - 기능 3에 대해 추가 처리 가능한 모델2 작성 (1)\n",
    "#### 모델 2는 모델 1에서 기능 3 지하철 트리거 인식 시 작동되는 모델임\n",
    "#### 모델 1에서 기능 3으로 분류(카테고리 :3) 인 경우 해당 모델에서 역별 분류 작업 수행\n",
    "#### 최종 수정일 : 20-05-27\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .npz 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## 1. 데이터 전처리\n",
    "### 1.1 wav 파일 로딩 및 피처 생성\n",
    "\n",
    "> [변경사항]\n",
    "- 피처를 최대한 많이 생성하여 데이터를 가공함 -> drop out 효과 극대화 및 과적합 방지, 정확도 향상\n",
    "- 이전 기능 별 분리되었던 모델(ver 2.*) 을 통합함\n",
    "- 각 데이터 별 193 피처 추출\n",
    "- row 통일 안함 (3~4sec)\n",
    "- 원핫인코딩 안함\n",
    "- 라벨을 1차원 배열로 변경 -> 카테고리 별 int값 출력하게 함\n",
    "* * *\n",
    "> [기존과 동일]\n",
    "- 기능 1,2에 대해 사용 데이터는 뉴욕대학교  MARL의 URBANSOUND8K DATASET 일부와 일상 생활에서 녹음한 녹음 파일(.wav)를 활용 (2,622개, 1.96G)\n",
    "- 기능 3에 대해 환승역 알림음을 트리거로 적용 (894개, 0.71G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wav 파일들의 피처 생성\n",
    "#librosa 사용\n",
    "#사용 특성은 mfcc, chroma_stft, melspectorgram, spectral_contrast, tonnetz로 총193\n",
    "#딥러닝 모델만 사용할 예정 -> 피처 축소 생략\n",
    "import glob\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오디오 불러오기 + 피쳐 생성\n",
    "# 피쳐 193개\n",
    "# row 통일 안시킴\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 가공\n",
    "#행렬로 변환\n",
    "def parse_audio_files(filenames):\n",
    "    rows = len(filenames)\n",
    "    # feature는 각 파일 별 row(window) * 피처 의 2차원 행렬\n",
    "    # labels은 파일 별 카테고리 int 값\n",
    "    features, labels = np.zeros((rows,193)), np.zeros((rows, 1))\n",
    "    i = 0\n",
    "    for fn in filenames:\n",
    "        try:\n",
    "            mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            y_col = int(fn.split('-')[0])\n",
    "        except:\n",
    "            print(\"error : \"+fn)\n",
    "        else:\n",
    "            features[i] = ext_features\n",
    "            labels[i] = y_col\n",
    "            print(y_col)\n",
    "            i += 1\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = []\n",
    "#0 : 사이렌\n",
    "#1 : 자동차가 다가오는 소리(엔진소리)\n",
    "#2 : 자동차 경적소리\n",
    "#4 : 환승역 안내음\n",
    "audio_files.extend(glob.glob('*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "print(len(audio_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "2\n",
      "2\n",
      "2\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "3\n",
      "3\n",
      "3\n",
      "30\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "4\n",
      "4\n",
      "4\n",
      "40\n",
      "40\n",
      "40\n",
      "41\n",
      "41\n",
      "41\n",
      "42\n",
      "42\n",
      "42\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "files = audio_files\n",
    "X, y= parse_audio_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.npz\n",
    "np.savez('data', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
